\documentclass{book}
\usepackage{listings}
\title{Appunti corso statistica ed R, prima parte}
\author{Andrea Berardi - and.be.like@gmail.com}
\begin{document}

% Email:		and.be.like@gmail.com
% Version:		0.0.3
% Purpose:		Attempt to write a short, easy and examples-oriented guide to statistics and probability
% Notes:		This document is still far to be ready in order to be shared

\maketitle

TO DO:
\begin{list}{*}{}
\item Generale
\begin{list}{-}{}
\item Revisione completa
\item Strutturare in modo intelligente, organizzato ed organico
\end{list}
\item Argomenti
\begin{list}{-}{}
\item Probabilit\`{a}: definizioni, variabili aleatorie
\item Distribuzioni fondamentali, discrete ed ac
\item Inferenza statistica e teoria dei test
\end{list}
\end{list}




\huge{Statistica descrittiva}
\normalsize \\ \\
La statistica descrittiva nasce dal bisogno e dalla necessit\`{a} di uno studio sistematico dei fenomeni reali, per una loro quantificazione numerica, dalla volont\`{a} di prevedere, sia all'indietro che in avanti, il comportamento di determinati caratteri, e per capire, quando si hanno insufficienti conoscenze, come agiscono e reagiscono dati elementi in situazioni stabilite.
La base della descrittiva \`{e}, ovviamente, l'osservazione: si suppone cio\`{e} che l'unit\`{a} oggetto di studio (cio\`{e} l'"unit\`{a} statistica") esprima un certo "carattere" con una propria "modalit\`{a}", e che essa sia \emph{osservabile}.
Ad esempio, un individuo può presentare la modalit\`{a} "azzurro" per il carattere "colore degli occhi". Si nota che per quanto riguarda le unit\`{a} statistiche e i vari caratteri osservati si possono trovare gli elementi più disparati.
Volendo fare una qualsiasi indagine per ottenere informazioni su un carattere di interesse in una popolazione, ovviamente in linea generale non si \`{e} interessati a conoscere le singole modalit\`{a} per ogni individuo del collettivo osservato, ma si cerca di definire dei riassunti di tali dati che permettano di descrivere sinteticamente gli individui osservati o, nel caso di campionamento da popolazioni finite, di fare affermazioni probabilistiche sull'intera popolazione.
Gli indici di sintesi in letteratura sono veramente numerosi, ma in questa sede ci si limita a prendere in esame solo quelli fondamentali che serviranno nel proseguo della lezione.
Gli indici descrittivi ovviamente dipendono dal tipo di carattere in esame: la media aritmetica del colore dei capelli ad esempio non avrebbe alcun senso.

Innanzitutto, \`{e} necessario fornire un semplice glossario di base:
\begin{list}{*}{}
\item collettivo: unit\`{a} statistiche su cui \`{e} stata effettuata la rilevazione o l'analisi dati. La sua numerosit\`{a} si riferisce al numero di unit\`{a} statistiche (oggetti dell'indagine, ricerca, ..) che comprende;
\item popolazione: insieme di riferimento da cui \`{e} estratto il campione statistico; la sua numerosit\`{a} si indica in genere con N;
\item campione: sottoinsieme della popolazione su cui vengono effettuate delle rilevazioni. Ciò \`{e} necessario in quanto l'indagine censuaria assume proporzioni e costi enormi, ed esistono strumenti statistico-probabilistici per estendere ipotesi testate sul campione all'intera popolazione di riferimento. La numerosit\`{a} campionaria in genere indicata con n;
\item frequenza (assoluta): numero di volte con cui si presenta un certo fenomeno, ci si riferisce ad essa con f oppure n;
\item frequenza relativa: \`{e} pari alla frequenza assoluta sul totale di casi, ovvero n/N oppure f/F. Per la legge debole dei grandi numeri tende, sotto larghe ipotesi, alla probabilit\`{a} dell'evento. Dalla frequenza realtiva derivano poi le percentuali, con una semplice moltiplicazione per 100;
\item carattere qualitativo: \`{e} un carattere non numerico, che può essere ordinato (es. insufficiente, sufficiente, buono) oppure sconnesso (es. blu, rosso, verde).
\item carattere quantitativo: \`{e} un carattere espresso numericamente, e può essere di tipo discreto o continuo. E' continuo se il suo campo di variazione \`{e} l'insieme dei numeri reali o comunque un insieme numerico denso, ed \`{e} discreto altrimenti. Alcuni carattere possono essere espressi sia in modo qualitativo che quantitativo, come ad esempio il peso.
\end{list}

Prendiamo inizialmente in esame solo gli indici di sintesi per ogni variabile separatamente, ovvero che analizzino distribuzioni semplici.

* Indici di locazione *

L'indice intuitivamente più semplice \`{e} certamente la moda, che si utilizza con qualsiasi tipo di carattere (volendo anche con quantitativi continui, ma perde facilmente di significato).
La moda \`{e} semplicemente la modalit\`{a} del carattere che si presenta più frequentemente nella distribuzione studiata, ovvero \`{e} la modalit\`{a} corrispondente alla maggiore frequenza assoluta nel collettivo.
Una moda può essere "Q", "cercopiteco" o "42". Se nella distribuzione di riferimento esistono più mode essa si dice bimodale, trimodale, etc.

Uno degli indici più utilizzato e noto \`{e} la media aritmetica semplice:

 $\mu_x=\sum_{i=1}^n \frac{x_i}{n}$


La media \`{e} un semplicissimo indice lineare per qualsiasi carattere non qualitativo sconnesso, che sintetizza in un numero (non puro) il valore centrale della distribuzione del carattere sulle unit\`{a} osservate. Ovviamente esistono molti altri tipi di medie (geometriche, quadratiche, pesate, etc).

Un altro indice particolarmente importante e robusto, per caratteri qualitativi ordinati o quantitativi, \`{e} la mediana, un indice che divide la distribuzione in due parti di uguale numerosit\`{a}; in altri termini, presenta valori inferiori alla mediana il 50\% del collettivo osservato (si taglia la funzione di ripartizione a met\`{a} lungo l'asse delle ordinate).
In realt\`{a} la mediana \`{e} un caso particolare di un altro indice, ovvero il percentile, che, come intuibile dal nome, divide la distribuzione in parti percentuali, ed un altra sintesi basata su di esso \`{e} il quartile, che divide la distribuzione in quarti: il primo quartile lascia alla propria sinistra il 25\% della popolazione, il terzo ne lascia il 25\% alla propria destra; il secondo quartile \`{e} proprio la mediana.
Da questi valori si disegna uno dei grafici fondamentali della descrittiva, il boxplot.

	-R-
esempio di un boxplot:

\lstset{language=R}
\lstinputlisting{snippets/boxplot.R}

Questo per quanto riguarda gli indici che descrivono dove si aggirano i valori medi, mediani o modali, ovvero dov'\`{e} il centro delle distribuzioni che si osservano. Ma [ESEMPI NECESSARI: anscombe!] questi valori danno solo un'idea di posizione, e non di forma. Infatti a parit\`{a} di questi indici possono corrispondere forme di distribuzioni molto diverse!

	-R-
esempio anscombe:

\lstinputlisting{snippets/anscombe.R}

**NOTA: per ripristinare il parametro mfrow come al default (1 plot per window), > par(mfrow=c(1,1));

Indici di forma

L'indice fondamentale di descrizione del comportamento di una distribuzione rispetto alla media \`{e} la varianza.
La varianza indica il grado di dispersione intorno alla media della distribuzione in esame: se tutti i punti sono coincidenti questa vale 0, altrimenti una quantit\`{a} positiva.

\begin{verbatim}
 *	sigma_x=sum{i from 1 to n} (x_i - mu_i)**2/(n-1)
\end{verbatim}

Tuttavia la varianza \`{e} un indice di difficile interpretazione, in parte anche per via della sua unit\`{a} di misura, il quadrato di quella di partenza. Si usa come indice equivalente la deviazione standard, che \`{e} la sua radice quadrata, in quanto essa possiede la stessa scala del carattere su cui \`{e} misurata.

Tuttavia a questo livello di analisi i soli numeri, se non accompagnati da un adeguato esame grafico, possono essere fuorvianti, specialmente per quanto riguarda gli indici di dispersione. A questo riguardo:

	-R-
\lstinputlisting{snippets/dispersione.R}

oppure:
grafici di normali... leptocurtiche, platocurtiche etc
In letteratura esistono una quantit\`{a} notevole di indici di dispersione, alcuni per determinate tipologie di variabili, alcuni per determinati scopi; ad esempio il range di variazione, il coefficiente di variazione, la varianza per graduatorie, etc.

Indici di sintesi di associazione e dipendenza

Per misurare la variazione congiunta di due variabili si vedr\`{a} in questa sede l'approccio simmetrico.
Indici simmetrici pongono allo stesso livello d'importanza le variabili esaminate, ovvero non si cerca di spiegare la variabilit\`{a} di una rispetto all'altra.

Per variabili qualitative sconnesse oppure ordinate l'indice più utilizzato \`{e} il chi quadro (sebbene spesso non sia il più adatto). Il chi quadro misura in generale la distanza della distribuzione congiunta da una situazione teorica di indipendenza, ovvero \`{e} nullo in caso di indipendenza e tanto più grande più si presenti associazione tra le variabili esaminate.
(formula)
Sebbene sia l'indicie più utilizzato in questa situazione, esso presenta dei problemi quando si vogliono confrontare diverse distribuzioni doppie, in quanto non ha limitazioni di scala e dunque non \`{e} un indice "relativo". Esistono tuttavia manipolazioni del chi quadrato che lo trasformano in un indice più facilmente interpretabile, sebbene non siano fortemente utilizzate (vv Phi di Cramer).

Per variabili quantitative (discrete o continue, ma non graduatorie) invece viene utilizzato l'indice di correlazione lineare di Bravais-Pearson, che misura il grado in cui le variabili in esame variano congiuntamente (covariano).
La correlazione \`{e} un indice limitato nell'intervallo [-1,1] ed assume valore unitario nel caso in cui ci sia una dipendenza funzionale (assenza di errore, relazione funzionale deterministica) tra le variabili, ed \`{e} nulla nel caso in cui vi sia indipendenza in forma lineare. E' sempre fondamentale l'analisi grafica di questa grandezza, in quanto una correlazione nulla può anche nascondere una relazione funzionale non lineare (es. quadratica). In particolare, la correlazione tra una variabile e se stessa non \`{e} altro che la varianza di questa.
(formula)

	* Applicazione: regressione lineare semplice *

A cosa servono tutti questi indici? E' una forma di inutile sadismo matematico, sono solo formulette per descrivere fenomeni oppure hanno un riscontro su tecniche di estrazione delle informazioni? La risposta \`{e} piuttosto ovvia, ed andremo a dimostrarlo con un piccolo, pratico esempio.
Uno degli scopi principe della statistica \`{e} storicamente l'individuazione di legami di causalit\`{a} e, soprattutto, il descrivere il "come" ed il "quanto" di queste relazioni.

Per questo esempio verr\`{a} utilizzato il noto dataset "trees", presente di default nella libreria di R. Questa indagine \`{e} condotta per la necessit\`{a} di prevedere il volume di alberi di ciliegio a partire da altezza e diametro, in modo tale da poter determinare i migliori candidati da abbattere.

Note sulla terminologia:
* Regressione semplice: modello statistico che pone in relazione una variabile di interesse (variabile risposta o dipendente) ed una variabile ad essa legata in una relazione causale asimmetrica, detta variabile dipendente, esplicativa, predittiva o covariata. In realt\`{a} questo modello, che appare di facile intuizione e comprensione, poggia su diverse ipotesi complesse, che per ora non andremo ad analizzare.
* Goodness of fit: bont\`{a} di adattamento, ovvero capacit\`{a} del modello di adattarsi ai dati. In generale viene calcolata esaminando la distanza tra valori predetti (o teorici) dal modello e i dati osservati su cui esso \`{e} stato stimato. L'indice utilizzato nel caso della regressione \`{e} l'R quadro.


\lstinputlisting{snippets/ex1.R}

Dov'\`{e} quindi l'utilit\`{a} di questo strumento? L'utilit\`{a} del modello regressivo \`{e} nella formalizzazione probabilistico-matematica, nella capacit\`{a} di studiare una variabile di interesse in ambito previsivo, descrittivo e relazionale (causale), nell'aprire le porte alle possibilit\`{a} dei test statistico-inferenziali, nel costituire un semplice ed intelleggibile punto di partenza per condurre indagini che coinvolgono metodi più complessi.
E se invece (come si accennava prima), volessimo inserire anche la variabile "altezza" tra i predittori del volume? Cosa accadrebbe al modello di regressione semplice?
Innanzitutto, la regressione passerebbe da semplice a multivariata (o multipla), tuttavia mantenendo la condizione di linearit\`{a}, essendo questa posta sui parametri. Ed ovviamente, l'interpolazione ai dati non sarebbe più rappresentabile da una retta ma, giacendo su R2, da un piano.
Proviamo con un modello semplice per avere un'idea di ciò che succede, innanzitutto analizzando i legami tra le variabili. (E' importante notare che le variabili esplicative devono possedere una correlazione non elevata, altrimenti ci si troverebbe in una situazione di collinearit\`{a} che invaliderebbe in toto il modello, portando a conclusioni del tutto prive di senso.)

\lstinputlisting{snippets/ex2.R}

		\emph{Probabilit\`{a}}

La probabilit\`{a} \`{e} strettamente legato alla statistica, un quanto permette di studiare la casualit\`{a}, e quindi di poter analizzare nel complesso le componenti sistematiche ed aleatorie di un certo fenomeno. In questo ambito, più che dilungarsi in ambito tecnico, si vedranno le definizioni fondamentali della probabilit\`{a}: definizione del concetto di probabilit\`{a}, assiomi di Kolmogorov, qualche teorema interessante come quello di Bayes, le distribuzioni di probabilit\`{a} più note e le caratteristiche delle variabili aleatorie.
Il concetto stesso di probabilit\`{a} \`{e} molto complesso, e diversi approcci hanno portato a diverse definizioni, che sono tuttavia compatibili ed in un certo senso complementari tra loro. E' interessante notare che la disciplina stessa \`{e} nata dalla necessit\`{a} di fare affermazioni in ambito ludico: i primissimi studi in questo campo sono infatti di Girolamo Cardano, esposti nel "Liber de ludo aleae" del 1526, mentre la formalizzazione assiomatica moderna \`{e} stata perfezionata solo nel 1933 da Kolmogorov.

1. La definizione classica:
La probabilit\`{a} di un evento \`{e} il rapporto tra il numero di casi favorevoli all'evento ed il numero dei casi possibili, purch\`{e} essi siano tutti equiprobabili.

\begin{verbatim}
 *	P(A)=n_A/n

Questa \`{e} la prima definizione dal punto di vista cronologico, ed \`{e} quella più facilmente intuibile. E' chiarissima la sua relazione con il gioco dei dadi!
I limiti di questo approccio sono tuttavia lampanti: il fenomeno deve essere completamente noto, i casi possibili devono essere in numero finito, e soprattutto questi devono essere equiprobabili. Inoltre, il concetto di probabilit\`{a} viene utilizzato all'interno della stessa definizione!
Ma facciamo un esempio, considerando il lancio di un dado.
Supponendo di lanciare un dado bilanciato a sei facce, quale sar\`{a} la probabilit\`{a} di ottenere un numero pari?
I casi possibili sono: {1, 2, 3, 4, 5, 6}, tutti equiprobabili perch\`{e} il dado \`{e} bilanciato.
Si ottiene quindi che i casi favorevoli all'evento {otterrò un numero pari} sono {2,4,6}, ovvero 3/6 = 0.5, ovvero si ha una probabilit\`{a} pari a 0.5 di ottenere un numero pari dal lancio di un dado bilanciato.
Si nota che, sebbene sia di uso comune, \`{e} opportuno riferirsi alle probabilit\`{a} con frazioni piuttosto che con percentuali, in quanto il loro uso può essere spesso fuorviante e dare adito ad interpretazioni non adeguate.

Da questa definizione segue che:
1.1. la probabilit\`{a} di un evento \`{e} un numero compreso tra 0 ed 1
1.2. la probabilit\`{a} dell'evento certo \`{e} pari ad 1
1.3. la probabilit\`{a} di due eventi incompatibili (ovvero che non possono verificarsi contemporaneamente) \`{e} pari alla somma delle due rispettive probabilit\`{a}

Facciamo dunque un altro esempio, sempre considerando il lancio di un dado: qual \`{e} la probabilit\`{a} di ottenere un risultato diverso da 6?
primo approccio - i casi favorevoli all'evento sono: {1, 2, 3, 4, 5} da cui si ricava che 5/6 \`{e} la probabilit\`{a} di questo evento
secondo approccio - poich\`{e} la probabilit\`{a} dell'evento certo \`{e} 1, e gli eventi {ottenere un risultato diverso da 6} ed {ottenere 6} sono due eventi incompatibili e necessari, la loro unione sar\`{a} proprio l'evento certo: infatti tirando un dado, otterrò 6 oppure un risultato diverso da 6. Quindi, poich\`{e} P{ottenere 6}=1/6, e poich\`{e} P{ottenere 6} + P{ottenere un numero diverso da 6} = P{evento certo} = 1, segue che P{ottenere un numero diverso da 6} = P{evento certo} - P{ottenere 6} = 1 - 1/6 = 5/6
Bench\`{e} questo secondo approccio sembri molto macchinoso applicato ad un caso così semplice, \`{e} spesso l'unico possibile in molte situazioni, e aiuta a capire quale sia la logica utilizzata molto spesso nei calcoli probabilistici.

2. La definizione frequentista:
Ipotizzando di poter ripetere lo stesso esperimento infinite volte nelle stesse condizioni, la probabilit\`{a} di un evento \`{e} il limite a cui tende la frequenza relativa dei casi favorevoli all'evento al crescere del numero degli esperimenti, ovvero

\begin{verbatim}
 *	P(A)= lim{n to Inf} n_A/n
\end{verbatim}

Questa definizione, di facile intuizione come quella classica, supera diversi limiti: innanzitutto la definizione non \`{e} più circolare, gli eventi non devono essere in numero finito ed inoltre non devono essere tutti necessariamente equiprobabili.
E' importante notare però che non sempre si hanno esperimenti che si possono - teoricamente - ripetere all'infinito.
Anche da questa definizione seguono le tre propriet\`{a} della probabilit\`{a} descritte precedentemente.

3. La definizione soggettiva:
La probabilit\`{a} di un evento \`{e} il prezzo che un individuo ritiene equo pagare per ricevere 1 se l'evento si realizza e 0 se esso non si realizzi; le probabilit\`{a} degli eventi devono essere distribuite in maniera tale che non sia possibile ottenere una vincita certa od una perdita certa (condizione di coerenza).

Anche da questa definizione derivano le tre propriet\`{a} fondamentali della probabilit\`{a}:
3.1 la probabilit\`{a} di un evento deve essere un numero compreso tra 0 ed 1, altrimenti si avrebbe vincita certa o perdita certa
3.2 


\end{document}


